{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use(\"TkAgg\")\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料：訓練集、測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      " (60000, 28, 28)\n",
      "y_train\n",
      " (60000,) 5\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('x_train\\n', x_train.shape)\n",
    "print('y_train\\n', y_train.shape, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "x_train = x_train.reshape(-1, 28*28)/255.\n",
    "x_test = x_test.reshape(-1, 28*28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構 Model，修改成CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=1024, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2363 - acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x103bbaa58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1, batch_size=64,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測新資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACpJJREFUeJzt3W9oXXcdx/HPd0lbav+sXYO4bqPtOmln2YZjcX0ig+LmsELQ2RXBdRUp2wO7ZwpDBhYre+Zk7IFD0P3TrnVkIMpE3RAL1qosox2zbN3UtqFEuy6SlqZp0p8PbgrXmfs9pid/evN5v6CQ5Jtz7yHbO+ckv5x7opQiAHPfVbO9AwBmBrEDJogdMEHsgAliB0wQO2CC2AETxN5GIuLvETESEV0f+vgbEVEiYvVlPOYzEbF7qvYRVy5ibz9/k/TlS+9ExC2SFs7e7qBdEHv7eV7Stqb3H5T03KV3IqI7IgYiorPpY/dFxBtVDxwRq8fPEL4aEccj4oOIeHj8MQ9FxGBEPNX0+Wsj4rWIeD8iTkXETyJiWdP89ojoi4ihiPhZROxtPouIiM+Pn5UMRsQfIuLWGl8XVCD29vNHSUsj4uaI6JC0VdILl4allD9Lel/S3U3bfEWNbxL/rzslfXz8sb8v6VuSPiNpg6T7I+Ku8c8LSY9LWinpZkk3SPq2JEXEfEkvS3pG0jWS9kj6wqUniIjbJf1I0kOSVkh6WtLPI2LBJPYTk0Ds7enS0f1uSUck9X9o/qwagSsirpH0WUk/ncTjf6eUMlxK+bWks5L2lFL+WUrpl7Rf0iclqZRytJTym1LK+VLKvyR9T9KlbwQbJXVKerKUcqGU0ivpT03PsUPS06WUg6WUsVLKs5LOj2+HadBZ/Sm4Aj0v6feS1qjpFL7JC5L+GhGLJd0vaX8p5eQkHn+g6e1zE7y/WJIi4qOSnpT0aUlL1Dh4fDD+eSsl9Zf/vtLqeNPbqyQ9GBE7mz42f3w7TAOO7G2olPIPNX5R9zlJvRPM+yUdUOO0+QFN7hR+Mh6XVCTdWkpZqsbZRIzPTkq6LiKi6fNvaHr7uKTvllKWNf37SCllzzTtqz1ib19fk7SplHK2xfw5Sd+UdIsaPztPhyWSzkgajIjrJH2jaXZA0pikr0dEZ0T0SPpU0/yHkh6OiDujYVFEbI6IJdO0r/aIvU2VUt4tpfwl+ZSX1ThVfjn5hlDXLkm3S/q3pF+q6SyjlDIi6YtqfFMaVOOo/ws1fi7X+L7vkPSUGqf+RyVtn6b9hKTgxSvmroh4V9JDpZTfzva+SFJEHJT0g1LKj2d7XxxxZJ+jIuI+NX6efm0W9+GuiPjY+Gn8g5JulfSr2dofd/w2fg6KiN9J+oSkB0opF2dxV9ZJ2qfGb+/flfSlSa4KYApxGg+Y4DQeMDGjp/ERwWkEMM1KKTHRxzmyAyaIHTBB7IAJYgdMEDtggtgBE8QOmCB2wASxAyaIHTBB7IAJYgdMEDtggtgBE8QOmCB2wASxAyaIHTBB7IAJYgdMEDtggtgBE8QOmCB2wASxAyaIHTBB7IAJYgdMEDtggtgBEzN6y2ZMLGLCO+xOyfZ1H7vOc0tSKa3v0n3x4sVaz509Nv4XR3bABLEDJogdMEHsgAliB0wQO2CC2AETrLNPgauuqvc9k/VmzASO7IAJYgdMEDtggtgBE8QOmCB2wASxAyZYZ58CddfJOzvz/wwrVqxI58uWLWs5W758ebrtmjVr0vmiRYvS+dVXX53O169f33K2YcOGdNtXX301nT/22GPpPLvW3vFvEziyAyaIHTBB7IAJYgdMEDtggtgBEyy9jau6TDVbXtu4cWO67aOPPprOu7u703lXV1c6nzdvXjqvY3R0NJ2PjIyk8/7+/pazEydOpNu+99576RyTw5EdMEHsgAliB0wQO2CC2AETxA6YIHbARMzkpX4RccVeV9jR0ZHOx8bGWs56e3vTbXt6etL5E088kc7feeeddH7y5MmWs8HBwXTbY8eOpfPh4eF0XrXOfvr06XSOqVdKmfDaXo7sgAliB0wQO2CC2AETxA6YIHbABLEDJlhnnwKHDx9O5319fel827ZtU7k7bWO2b3U9V7HODpgjdsAEsQMmiB0wQeyACWIHTBA7YMLmdeOz2/dK9W7hu2DBgnR+/vz5dF51LX3VLZ2rXts9U/fvLOpszzr5zOLIDpggdsAEsQMmiB0wQeyACWIHTBA7YMJmnX06Va01V62jV/0NQJVs+6p9qztH++DIDpggdsAEsQMmiB0wQeyACWIHTLD0NgWqls7OnTuXzqsuUa1zCWtdVcuGVZepsnR35eDIDpggdsAEsQMmiB0wQeyACWIHTBA7YIJ19ikwPDyczteuXZvOd+7cmc5XrlyZzk+fPt1ytn///nTbqttJV70MdpXstsy8lPTM4sgOmCB2wASxAyaIHTBB7IAJYgdMEDtgImbyeuOImLWLm+vesnnevHktZ2+//Xa67erVq9P5mTNn0vnZs2fT+dKlS1vOFi5cmG576tSpdP7iiy+m8927d6fzgYGBlrNsDV5iHf5ylVIm/J+dIztggtgBE8QOmCB2wASxAyaIHTBB7IAJm3X2urJ1+kceeSTddmRkJJ3v3bs3nQ8NDaXzJUuWtJx1d3en227evDmd79ixI51XrdP39PS0nL3++uvptqzDXx7W2QFzxA6YIHbABLEDJogdMEHsgAliB0ywzo5U1bX4vb296XzdunUtZ5s2bUq3PXjwYDpnHX5irLMD5ogdMEHsgAliB0wQO2CC2AETLL1NgY6OjlrbT+cSUdXyVNVLbI+OjqbzxYsXp/MDBw60nFXdDvqOO+5I53VfHnyuYukNMEfsgAliB0wQO2CC2AETxA6YIHbABOvsSGW3qpakCxcupPMtW7a0nO3bty/d9rbbbkvnhw4dSufZ3xjM5ctfWWcHzBE7YILYARPEDpggdsAEsQMmiB0w0TnbO4Ar29jYWDqvul6+r6+v5axqrXv9+vXpvGqdvep6dzcc2QETxA6YIHbABLEDJogdMEHsgAliB0ywzt4GqtaLs7XuqtcrqPPYUvX17Nlr6lc99tDQUDrH5HBkB0wQO2CC2AETxA6YIHbABLEDJlh6awNVy2dVl6HWUfXYXV1d6XzXrl0tZ1W3bH7zzTfTeRXXWza3wpEdMEHsgAliB0wQO2CC2AETxA6YIHbABOvsbWDVqlXp/Nprr205q1prvvHGG9P51q1b0/m9996bzufPn99ytn379nTb48ePp/OqS2Tn8m2ZLwdHdsAEsQMmiB0wQeyACWIHTBA7YILYARMxk9f8RsScvMC47q2Bq7Z/5ZVX0vk999xT6/kzR44cSed79uxJ5y+99FLL2VtvvZVuW/V14Xr1iZVSJvzCcWQHTBA7YILYARPEDpggdsAEsQMmiB0wwTp7G7jpppvS+fXXX99yVnVL5YGBgXR+9OjRdF4H16NPD9bZAXPEDpggdsAEsQMmiB0wQeyACWIHTLDOjlo6O/NbD2Rr5ayjTw/W2QFzxA6YIHbABLEDJogdMEHsgAlu2dwGqi4FrfNS1lVLr1Xz0dHRy35uzCyO7IAJYgdMEDtggtgBE8QOmCB2wASxAyZYZ28DXAqKqcCRHTBB7IAJYgdMEDtggtgBE8QOmCB2wMSMvpQ0gNnDkR0wQeyACWIHTBA7YILYARPEDpggdsAEsQMmiB0wQeyACWIHTBA7YILYARPEDpggdsAEsQMmiB0wQeyACWIHTBA7YILYARPEDpggdsDEfwBJQIUBIU2FhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00539619e-05 3.61170223e-08 8.08167101e-07 6.70247851e-03\n",
      "  1.27175645e-06 9.80665505e-01 5.84191640e-10 1.51099721e-06\n",
      "  1.07821565e-04 1.25104971e-02]]\n",
      "Predicted class : 5\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"./my_image1.png\")\n",
    "print(np.array(im).shape)\n",
    "\n",
    "im = im.resize((28, 28), Image.ANTIALIAS) #resize the image\n",
    "im = np.array(im) #convert to an array\n",
    "im2 = im/np.max(im).astype(float) #normalise input\n",
    "\n",
    "plt.imshow(im2, cmap='gray')\n",
    "plt.title('My Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "test_image = np.reshape(im2, [1,784]) # reshape it to our input placeholder shape\n",
    "\n",
    "p_ = model.predict(test_image)\n",
    "print(p_)\n",
    "h_ = np.argmax(p_)\n",
    "print(\"Predicted class : {}\" .format(h_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
